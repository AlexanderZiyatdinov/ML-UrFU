{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc6aca7",
   "metadata": {},
   "source": [
    "# Домашнее задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de07e1c",
   "metadata": {},
   "source": [
    "Все задачи должны быть выполнены с помощью внутренних функций numpy, pandas и sklearn. Не используй AI при решении, попробуй всё сделать сам либо попроси LLM немного помочь, но не решать всё за тебя. Это не сложно :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775663b3",
   "metadata": {},
   "source": [
    "## Задание 1. Мой KNN (1 балл)\n",
    "\n",
    "\n",
    "Если вы вдруг забыли что такое knn, то можете обратиться к материалам первой лекции или посмотреть [здесь](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).\n",
    "\n",
    "Ваша задача реализовать свой простой `KNNClassifier` для бинарных данных. Вам нужно реализовать 4 метода:\n",
    "1. `__init__` - начальная инициализация\n",
    "2. `fit` - обучение классификатора\n",
    "3. `predict` - предсказание для новых объектов\n",
    "4. `predict_proba` - предсказание вероятностей новых объектов\n",
    "\n",
    "Следуйте подсказкам в комментариях и `docstrings` и всё обязательно получится :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k: int=...) -> None:\n",
    "        \"\"\"\n",
    "        :param k: Количество ближайших соседей. По умолчанию, равняется 3.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train: np.array):\n",
    "        \"\"\"\n",
    "        :param X_train: train выборка\n",
    "        :param y_train: train ответы\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Обучение в алгоритме knn сводится к запоминанию всей тренировочной выборки и ответов на неё.\n",
    "        ### Сохраните обучающую выборку в аттрибуты класса:\n",
    "        # self.X_train = ...\n",
    "        # self.y_train = ...\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param X_test: тестовая выборка\n",
    "        :return: предсказанные метки для X_test\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        for x in X_test:\n",
    "        # Для каждой тестовой точки нужно найти k ближайших соседей среди обучающих данных\n",
    "\n",
    "        ### Вычислите евклидово расстояние от x до всех точек в self.X_train:\n",
    "        # distances = [ ... for x_train in self.X_train]\n",
    "\n",
    "        ### Найдите индексы k ближайших соседей (самых маленьких расстояний):\n",
    "        # k_indices = ...\n",
    "\n",
    "        ### Получите метки этих соседей из self.y_train:\n",
    "        # k_labels = ...\n",
    "\n",
    "        ### Определите самую частую метку среди соседей (используйте Counter или np.bincount):\n",
    "        # most_common = ...\n",
    "\n",
    "        ### Добавьте most_common в список predictions:\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def predict_proba(self, X_test: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param X_test: тестовая выборка\n",
    "        :return: вероятности принадлежности к классам для X_test\n",
    "        \"\"\"\n",
    "        probabilities = []\n",
    "\n",
    "        for x in X_test:\n",
    "        # Для каждой тестовой точки вычисляем вероятности принадлежности к классам\n",
    "\n",
    "        ### Вычислите евклидово расстояние от x до всех точек в self.X_train:\n",
    "        # distances = [ ... for x_train in self.X_train]\n",
    "\n",
    "        ### Найдите индексы k ближайших соседей:\n",
    "        # k_indices = ...\n",
    "\n",
    "        ### Получите метки этих соседей:\n",
    "        # k_labels = ...\n",
    "\n",
    "        ### Подсчитайте частоту каждого класса (предполагаем классы 0 и 1):\n",
    "        # class_counts = ...\n",
    "        # prob_class_0 = ...\n",
    "        # prob_class_1 = ...\n",
    "\n",
    "        ### Добавьте [prob_class_0, prob_class_1] в список probabilities:\n",
    "        # probabilities.append()\n",
    "        return np.array(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751fc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тест 1.1: Проверка predict и predict_proba на простых данных\n",
    "X_train = np.array([[1, 1], [1, -1], [-1, -1], [-1, 1]])\n",
    "y_train = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = KNNClassifier(k=3).fit(X_train, y_train)\n",
    "X_test = np.array([[0.5, 0.5], [-0.5, -0.5]])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "expected_pred = np.array([1, 0])\n",
    "expected_prob = np.array([[1/3, 2/3], [2/3, 1/3]])\n",
    "\n",
    "assert np.array_equal(y_pred, expected_pred), f\"predict: ожидалось {expected_pred}, получено {y_pred}\"\n",
    "assert np.allclose(y_prob, expected_prob, atol=0.01), f\"predict_proba: ожидалось {expected_prob}, получено {y_prob}\"\n",
    "\n",
    "# Тест 1.2: Проверка с k=1 (ближайший сосед)\n",
    "model_k1 = KNNClassifier(k=1).fit(X_train, y_train)\n",
    "y_pred_k1 = model_k1.predict(np.array([[0.5, 0.5]]))\n",
    "assert y_pred_k1[0] == 1, f\"При k=1 точка [0.5,0.5] должна быть классом 1, получено {y_pred_k1[0]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c746fb",
   "metadata": {},
   "source": [
    "## Задание 2.1. Чистим, масштабируем, предсказываем (1 балл)\n",
    "\n",
    "В этой задаче вам нужно будет применить алгоритм классификации `KNN` (можете воспользоваться своим из предыдущей задачи) и осуществить `preprocessing` данных. Файл лежит в `data`, а называется `hw2_task2_1.csv`.\n",
    "\n",
    "В первой части задания надо сделать следующее:\n",
    "\n",
    "1. `Обработайте пропущенные значения`: найдите все пропуски (`NaN`) в числовых признаках и заменить их на медиану соотв. признака\n",
    "2. `Выбросы`: проанализируйте столбец `income` на наличие выбросов. Если выбросы найдены, то заменить их на медиану соотв. признака. воспользуйтесь [методом IQR](https://habr.com/ru/companies/skillfactory/articles/848858/) для определения выброса.\n",
    "3. `Масштабирование данных`: примените стандартизацию `StandardScaler` ко всем числовым признакам\n",
    "4. `Кодирование кат. признаков`: Преобразуйте категориальный признак с помощью `One-Hot Encoding`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fbae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 0. Загрузка данных\n",
    "\n",
    "df = pd.read_csv(...)\n",
    "\n",
    "num_features = ['age', 'income', 'credit_score']  # Все числовые признаки\n",
    "cat_features = ['education']  # Все категориальные признаки\n",
    "\n",
    "# 1. Обработка пропущенных значений\n",
    "\n",
    "### Ваш код здесь ###\n",
    "\n",
    "# 2. Обработка выбросов в столбце income\n",
    "\n",
    "### Ваш код здесь ###\n",
    "\n",
    "# 3. Масштабирование числовых признаков\n",
    "\n",
    "### Ваш код здесь ###\n",
    "\n",
    "# 4. One-Hot Encoding категориальных признаков\n",
    "\n",
    "### Ваш код здесь ###\n",
    "\n",
    "# 5. Сохраните полученный датасет в файл hw2_task2_1_ans.csv\n",
    "\n",
    "### Ваш код здесь ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0fd740",
   "metadata": {},
   "source": [
    "## Задание 2.2. Чистим, масштабируем, предсказываем (1 балл)\n",
    "\n",
    "В этой задаче вам нужно будет применить алгоритм классификации `KNN` (можете воспользоваться своим из предыдущей задачи) и осуществить `preprocessing` данных\n",
    "\n",
    "Во второй части задания надо сделать следующее:\n",
    "\n",
    "1. `Cross-validation`: разделите данные на `train` (80%) и `test` (20%) с помощью `train_test_split`. Установите значение параметров `random_state=42` и `stratify=y` для сохранения пропорций классов.\n",
    "2. Создайте модель KNN классификатора. Можно использовать свой из предыдущей задачи.\n",
    "3. `Поиск гиперпараметра`: Подберите оптимальный гиперпараметр `k`. Протестируйте значения `k` от 1 до 15, посчитайте `accuracy` на тестовой выборке.\n",
    "4. Визуализируйте результат зависимости `accuracy` от значения гиперпараметра `k`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e876f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "# 0. Загрузка данных\n",
    "\n",
    "df = pd.read_csv(...)\n",
    "\n",
    "# 1. Разделение на обучающую и тестовую выборки\n",
    "\n",
    "### Ваш код здесь ###\n",
    "\n",
    "# 2. Реализация KNN классификатора (если используете готовый или уже модель уже реализована, то можно пропустить шаг)\n",
    "\n",
    "### Ваш код здесь ###\n",
    "\n",
    "# 3. Подбор оптимального k\n",
    "\n",
    "k_values = range(1, 16)\n",
    "accuracies = []\n",
    "\n",
    "### НАПИШИТЕ КОД ЗДЕСЬ ###\n",
    "# Для каждого значения k:\n",
    "# 1. Создайте модель KNN с данным k\n",
    "# 2. Обучите модель на обучающей выборке (не забудьте передать в самописную модель данные в виде <df.values>)\n",
    "# 3. Сделайте предсказания на тестовой выборке\n",
    "# 4. Вычислите точность и сохраните в список accuracies\n",
    "# 5. Выведите результат\n",
    "\n",
    "# 4. Визуализация результатов\n",
    "### НАПИШИТЕ КОД ЗДЕСЬ ###\n",
    "# Постройте график зависимости точности от k\n",
    "# Подпишите оси: 'k' и 'Accuracy'\n",
    "# Добавьте заголовок и сетку\n",
    "\n",
    "# 5. Вывод оптимального результата\n",
    "optimal_k = k_values[np.argmax(accuracies)]\n",
    "print(f'Optimal value: {optimal_k}')\n",
    "print(f'best score: {max(accuracies):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb98d2",
   "metadata": {},
   "source": [
    "# Задание 3. Очень вкусное задание (1 балл)\n",
    "\n",
    "Нужно немного передохнуть после предыдущего задания. Здесь всё очень просто. \n",
    "В этом задании вам нужно познакомиться с `Наивным байесовским классификатором`. Данная модель содержится реализована в `sklearn.naive_bayes.MultinomialNB`\n",
    "\n",
    "Вам необходимо:\n",
    "1. Создать список с `едой` и список с `It-терминами` (это будут ваши объекты, а ответы на них метки 0 и 1 соответственно)\n",
    "2. Объединить два списка в один и преобразовать все слова в векторы\n",
    "3. Обучите модель `MultinomialNB` с помощью метода `fit`\n",
    "4. Сделайте предсказание при помощи `predict`\n",
    "\n",
    "**Дополнительно**:\n",
    "Вы можете посмотреть ещё вот этот видос для пущего понимания тервера:\n",
    "[Теорема Байеса](https://vkvideo.ru/video-163894411_456239051)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6617688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "food = ['pizza', 'pasta', ] # Продолжите список до 10 слов\n",
    "it = ['java', 'python',]    # Продолжите список до 10 слов\n",
    "\n",
    "\n",
    "vect = CountVectorizer()  # Специальный инструмент, который переведет текст в числовые векторы (подробно пока не смотрим)\n",
    "X = vect.fit_transform(food + it)\n",
    "y = ...  # Создайте список меток классов (ответы) (0 для еды и 1 для IT)\n",
    "\n",
    "# Создаём модель (по умолчанию)\n",
    "model = ...\n",
    "\n",
    "# Обучаем модель при помощи метода fit\n",
    "model.fit(..., ...)\n",
    "\n",
    "# 3. Трансформируем новый текст через тот же vect (можете ввести свой текст)\n",
    "test = vect.transform(['I love python'])\n",
    "# 4. Результат:\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f4c3a",
   "metadata": {},
   "source": [
    "## Задание 4. Злобные твиты (1 балл)\n",
    "\n",
    "Наивный Байес очень хорошо подходит для Анализа тональности текста. То есть определить несет текст позитивный или негативный вайб :)\n",
    "\n",
    "В данной задаче вам даны твиты про разные авиакомпании (файлы `tweets_train.csv`, `tweets_test.csv`). Требуется построить классификатор, который бы определял имеет ли твит положительную или негативную окраску. Напишите функцию `predict`, который возвращает массив, где `1` - это позитивный, `0` - негативный.\n",
    "\n",
    "В данной задаче вам понадобятся `TweetTokenizer` (из модуля `nltk.tokenize`) и `CountVectorizer`. \n",
    "\n",
    "* `TweetTokenizer` самостоятельно разбивает строку на слова, предварительно проведя с ними несколько модификаций.\n",
    "* `CountVectorizer` превращает предложение в вектор чисел основываясь на их частоте, используя токенизатор.\n",
    "\n",
    "Задача делится на 2 пункта:\n",
    "\n",
    "1. `Preprocessing`: переведите все слова в нижний регистр, токенизируйте слова с помощью TweetTokenizer, а дальше опять соберите в предложение. Проделайте это и в `X_train` и `X_test`\n",
    "​\n",
    " \n",
    "2. `Predict`: переведите предложения в вектора количеств с помощь `CountVectorizer`. Обучите модель на данных и предскажите ответ.\n",
    "Чтобы получить баллы надо побить `accuracy = 0.88`\n",
    "\n",
    "P.S Можете посмотреть топ слов, которые с наибольшей вероятностью относятся к позитивным и негативным классам.\n",
    "\n",
    "P.P.S. Если ничего не понятно: можете изучить различные kernel на [kaggle](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q nltk\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def predict(df_train: pd.DataFrame, df_test: pd.DataFrame) -> np.ndarray:\n",
    "    ### Ваш код здесь (попробуйте проделать весь путь сами, мы напишем только окончание)\n",
    "\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('../data/tweets_train.csv')\n",
    "df_test = pd.read_csv('../data/tweets_test.csv')\n",
    "predict(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5980d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тесты\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = predict(df_train, df_test)\n",
    "y_true = df_test['airline_sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 0}).values\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "assert acc >= 0.88, f\"Accuracy = {acc:.3f} < 0.88. Модель недостаточно точная!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
